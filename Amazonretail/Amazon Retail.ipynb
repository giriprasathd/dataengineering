{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b5af980-e7f5-4a89-b5b2-a3c74a9a5797",
   "metadata": {},
   "source": [
    "# Amazon Retail data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b67fc3-fef6-4c0e-a43e-a91f83c789f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-S67TFTS4:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>amzaon</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x230f7985b50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "spark = SparkSession.builder.appName(\"amzaon\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d05b69d7-8f22-4247-8f78-b582adca28cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyarrowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached pyarrow-17.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\girib\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Pyarrow) (1.26.4)\n",
      "Downloading pyarrow-17.0.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/25.1 MB 14.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.4/25.1 MB 9.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.5/25.1 MB 8.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.5/25.1 MB 8.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.5/25.1 MB 8.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.5/25.1 MB 8.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.7/25.1 MB 3.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 5.8/25.1 MB 3.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.6/25.1 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 8.1/25.1 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 8.9/25.1 MB 3.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 10.0/25.1 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.5/25.1 MB 4.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.6/25.1 MB 4.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.6/25.1 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.5/25.1 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.5/25.1 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.1/25.1 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.4/25.1 MB 4.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 21.2/25.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.6/25.1 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 5.1 MB/s eta 0:00:00\n",
      "Installing collected packages: Pyarrow\n",
      "Successfully installed Pyarrow-17.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install Pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bbba1b2-d742-4459-8748-00909b9d0309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\girib\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\pandas\\__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f73841f-172a-47ac-a378-73ca61c06ba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_excel() got an unexpected keyword argument 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./datasets/Amazon Sale Report edit.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\pandas\\namespace.py:1184\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m   1181\u001b[0m     io_or_bin \u001b[38;5;241m=\u001b[39m io\n\u001b[0;32m   1182\u001b[0m     single_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1184\u001b[0m pdf_or_psers \u001b[38;5;241m=\u001b[39m \u001b[43mpd_read_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio_or_bin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_file:\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pdf_or_psers, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\pandas\\namespace.py:1147\u001b[0m, in \u001b[0;36mread_excel.<locals>.pd_read_excel\u001b[1;34m(io_or_bin, sn, sq)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpd_read_excel\u001b[39m(\n\u001b[0;32m   1145\u001b[0m     io_or_bin: Any, sn: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, List[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]], \u001b[38;5;28;01mNone\u001b[39;00m], sq: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m   1146\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio_or_bin\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mio_or_bin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbytearray\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mio_or_bin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmangle_dupe_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmangle_dupe_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: read_excel() got an unexpected keyword argument 'squeeze'"
     ]
    }
   ],
   "source": [
    "df=ps.read_excel(\"./datasets/Amazon Sale Report edit.xlsx\",header=True)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fca26a-2f6f-4ff1-8d1e-f40c6f098f2b",
   "metadata": {},
   "source": [
    "1. Calculate the total quantity (Qty) sold for each Category using groupBy and expr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d97c9e7-dbea-4acd-bf1d-1d4e779ce0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|     Category|Total|\n",
      "+-------------+-----+\n",
      "| Ethnic Dress| 1053|\n",
      "|          Top| 9903|\n",
      "|          Set|45289|\n",
      "|        Saree|  152|\n",
      "|       Bottom|  398|\n",
      "|Western Dress|13943|\n",
      "|       Blouse|  863|\n",
      "|        kurta|45045|\n",
      "|      Dupatta|    3|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df[\"Category\"]).agg(F.expr(\"sum(Qty) as Total\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc6415-d52b-43f4-b95c-f729fde3674e",
   "metadata": {},
   "source": [
    "2. Find the total revenue (Amount) for each Sales Channel using groupBy and expr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df951561-c4b0-41ce-b16a-a5049333378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+\n",
      "|Sales Channel |      Total_revenue|\n",
      "+--------------+-------------------+\n",
      "|    Non-Amazon|               NULL|\n",
      "|     Amazon.in|7.859267829999994E7|\n",
      "+--------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df[\"Sales Channel \"]).agg(F.expr(\"sum(amount) as Total_revenue\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ed340-639c-40ad-9a1a-5e282880585b",
   "metadata": {},
   "source": [
    "3. Determine the average Amount spent on orders based on the ship-state using groupBy and expr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ba5312b-5c29-4350-b94a-67e7e0245ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|       ship-state|average|\n",
      "+-----------------+-------+\n",
      "|            bihar| 1432.0|\n",
      "|           LADAKH| 914.01|\n",
      "|           Sikkim|  901.0|\n",
      "|            delhi| 827.68|\n",
      "|       Chandigarh| 823.15|\n",
      "|         NAGALAND| 801.29|\n",
      "|      LAKSHADWEEP| 793.82|\n",
      "|           SIKKIM| 738.64|\n",
      "|          Mizoram|  735.0|\n",
      "|           Punjab| 733.77|\n",
      "|            Bihar| 733.07|\n",
      "|            BIHAR| 720.61|\n",
      "|          MANIPUR| 714.02|\n",
      "|ARUNACHAL PRADESH| 710.71|\n",
      "|  JAMMU & KASHMIR| 704.06|\n",
      "|        RAJASTHAN| 695.62|\n",
      "| HIMACHAL PRADESH| 695.25|\n",
      "|           ODISHA| 694.79|\n",
      "|          HARYANA| 688.18|\n",
      "|    UTTAR PRADESH|  685.3|\n",
      "+-----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = df.groupBy(\"ship-state\").agg(F.expr(\"round(avg(amount), 2) as average\"))\n",
    "s = s.orderBy(F.desc(\"average\"))\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0f16b4-b9c1-4f4d-a07f-4a3f396d3233",
   "metadata": {},
   "source": [
    "4. Group orders by Courier Status and count the number of orders in each status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54910090-fda6-4b64-a244-502e78fff478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Courier Status| count|\n",
      "+--------------+------+\n",
      "|       Shipped|109487|\n",
      "|          NULL|  6872|\n",
      "|     Cancelled|  5935|\n",
      "|     Unshipped|  6681|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df[\"Courier Status\"]).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a6372-9f9b-4485-b0d6-4c46319464e3",
   "metadata": {},
   "source": [
    "5.Use groupBy and expr to find the maximum and minimum Amount spent per Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a917fd56-606c-482a-a273-30cda18c92c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+-----+\n",
      "|     Category|    Max|  min|\n",
      "+-------------+-------+-----+\n",
      "| Ethnic Dress| 1449.0|  0.0|\n",
      "|          Top| 1797.0|  0.0|\n",
      "|          Set| 5584.0|  0.0|\n",
      "|        Saree| 2058.0|  0.0|\n",
      "|       Bottom|1028.58|  0.0|\n",
      "|Western Dress| 2860.0|  0.0|\n",
      "|       Blouse|1266.66|  0.0|\n",
      "|        kurta| 2796.0|  0.0|\n",
      "|      Dupatta|  305.0|305.0|\n",
      "+-------------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df[\"Category\"]).agg(F.expr(\"max(Amount) as Max\"),F.expr(\"min(Amount) as min\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9644fdb3-920e-4304-9318-3b63c7dfb70d",
   "metadata": {},
   "source": [
    " Find the count of orders per Status and Fulfilment type using groupBy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe8c35e-79e7-4ff7-96c1-84d5c4477e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|Fulfilment|count|\n",
      "+----------+-----+\n",
      "|  Merchant|39277|\n",
      "|    Amazon|89698|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df[\"Fulfilment\"]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e23bdd-21bc-4248-bd47-8c21ee66fa0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'Order ID',\n",
       " 'Date',\n",
       " 'Status',\n",
       " 'Fulfilment',\n",
       " 'Sales Channel ',\n",
       " 'ship-service-level',\n",
       " 'Style',\n",
       " 'SKU',\n",
       " 'Category',\n",
       " 'Size',\n",
       " 'ASIN',\n",
       " 'Courier Status',\n",
       " 'Qty',\n",
       " 'currency',\n",
       " 'Amount',\n",
       " 'ship-city',\n",
       " 'ship-state',\n",
       " 'ship-postal-code',\n",
       " 'ship-country',\n",
       " 'promotion-ids',\n",
       " 'B2B',\n",
       " 'fulfilled-by',\n",
       " 'Unnamed: 22']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bde9fd-8733-437f-9e3a-8e9513e5933a",
   "metadata": {},
   "source": [
    "Calculate the sum of Amount for each ship-country using groupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa7d9f89-62b9-4ff4-bf90-3aa2424c3e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|ship-country| count|\n",
      "+------------+------+\n",
      "|        NULL|    33|\n",
      "|          IN|128942|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"ship-country\").agg(F.count(\"*\").alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5222ecdd-5012-491c-bea4-e7af7075bd12",
   "metadata": {},
   "source": [
    "Use groupBy to determine the number of unique SKU items sold per ship-city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2ae70d1-15b8-4510-ade6-d35fe339f91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|           ship-city|Unique|\n",
      "+--------------------+------+\n",
      "|           Bangalore|   582|\n",
      "|             GWALIOR|   128|\n",
      "|        CHEKONIDHARA|     3|\n",
      "|         KODUNGALLUR|     7|\n",
      "|            JHINJHAK|     2|\n",
      "|NANDIVARAM GUDUVA...|    49|\n",
      "|        Kudukkimotta|     6|\n",
      "|   Avinashi, Tirupur|     7|\n",
      "|           Neelipudi|     1|\n",
      "|VERAVAL RAJKOT DI...|     3|\n",
      "|          Naranapura|     1|\n",
      "|              Kathua|     3|\n",
      "|             SHIMOGA|     3|\n",
      "|             SANGRUR|    13|\n",
      "|        Chandauli UP|     1|\n",
      "|ERANHOLI, Thalassery|     1|\n",
      "|              Sanand|     1|\n",
      "|                TEOK|     2|\n",
      "|        VADAKKUMMURI|     3|\n",
      "|          REIS MAGOS|     5|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"ship-city\").agg(F.countDistinct(\"SKU\").alias(\"Unique\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5761fb8-89a8-4c49-b053-b436d698ff45",
   "metadata": {},
   "source": [
    "9. Find the maximum Amount for each ship-service-level across all States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ccded26-9eca-45a5-97f2-5b7ba8ffd66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+------+\n",
      "|ship-service-level|       ship-state|amount|\n",
      "+------------------+-----------------+------+\n",
      "|         Expedited|ARUNACHAL PRADESH|1477.0|\n",
      "|         Expedited|            ASSAM|1523.0|\n",
      "|         Expedited| HIMACHAL PRADESH|1556.0|\n",
      "|         Expedited|           KERALA|1776.0|\n",
      "|          Standard|           PUNJAB|5495.0|\n",
      "|         Expedited|           punjab|1115.0|\n",
      "|         Expedited|             NULL|1112.0|\n",
      "|          Standard|       TAMIL NADU|2372.0|\n",
      "|          Standard|              Goa| 999.0|\n",
      "|          Standard|              GOA|1695.0|\n",
      "|          Standard|            Bihar|1186.0|\n",
      "|         Expedited|          MANIPUR|1523.0|\n",
      "|          Standard|          HARYANA|2796.0|\n",
      "|         Expedited|        rajasthan| 885.0|\n",
      "|         Expedited|        TELANGANA|2664.0|\n",
      "|         Expedited|        MEGHALAYA|1442.0|\n",
      "|         Expedited|       Puducherry| 568.0|\n",
      "|         Expedited|       PUDUCHERRY|1449.0|\n",
      "|         Expedited|          MIZORAM|1271.0|\n",
      "|          Standard|           ODISHA|1695.0|\n",
      "+------------------+-----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby([\"ship-service-level\",\"ship-state\"]).agg(F.max(\"Amount\").alias(\"amount\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8266629-e8a5-4070-be69-62c3a592666b",
   "metadata": {},
   "source": [
    "Determine the number of unique ASIN products sold in each Category."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
